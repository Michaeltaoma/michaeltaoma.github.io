---
layout: post
updated: 2020-05-08 16:40
---

刚刚突然接到了java面试的通知，具体的时间还没有定下来。今天是周五，所以面试最快也得两天之后，趁这两天时间，根据网上的java知识导图，把java的知识全部复习（预习）一遍。首先下面列举一下需要学习/温习的知识，总共分为五大类
1. Java基础知识
2. 面向对象
3. 常用API
4. 集合I/O
5. 多线程、网络编程、反射、设计模式

这里是我找到的<a href = "https://www.cnblogs.com/java1024/p/8757952.html">思维导图的原地址</a>，衷心祝愿莘莘学子可以在平时下功夫学习而不是像我这样临时抱佛脚。以上的知识点分类相当全面，我个人的话，对于第四和第五点尤其不熟悉，所以应该会花上比较多的功夫去学习。

#### HashMap
- HashMap是刚刚尚未计划就开始的点，不管怎么样先把东西记在这里。
- HashMap是一个实现了Map接口的基于哈希表的类
	- Map接口：Map是java中的一个接口。他为数据（键值对）提供了一种映射，这个映射可以一对一地把键映射到值。在java中，有很多实现了Map接口，HashMap就是其中一个
	- 哈希表：哈希表（Hash table）是根据键而直接访问在内存储位置的数据结构。在访问一个键值对时，我们通过键去找值，这时候可以利用hash function（哈希函数）去找到键对应的存储位置<code>hash(key);</code>。然后访问对应的存储地址可以找到值。理论上来讲，用这种方式去访问数据，如果没有冲突的话，他的复杂度仅仅为O(1)。
- 其实在了解了哈希表之后，HashMap就没什么难的了，HashMap中既有map的键值对特点，也有哈希表的特点。当HashMap实例化的时候，一个数组会随之生成，当通过HashMap中的<code>public V put(K key, V value)</code>的方法的时候，会先通过哈希函数找到这个键对应的数组中的位置，然后尝试把值放入这个位置中去
	- 为什么说是尝试呢？因为哈希表的有个很大的缺陷就是，有可能会把不同的键映射到同一个地方。如果这种情况出现的话，**就会把这个值放入对应的位置的链表里面**，没错，在这个数组里面，每个元素同时也是一个可以储存多个值的链表
那么当进行查找<code>public V get(K key)</code>的时候，一样的先通过哈希函数得到位置，如果此位置只有一个元素的话直接取值，如果此位置有多个元素的话，需要遍历这个链表去查找。
- 以下是一个HashMap的部分数据
```java
public class HashMap<K,V> extends AbstractMap<K,V>
implements Map<K,V>, Cloneable, Serializable {
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; 
static final int MAXIMUM_CAPACITY = 1 << 30;  
static final float DEFAULT_LOAD_FACTOR = 0.75f; //默认负载因子0.75
static final int TREEIFY_THRESHOLD = 8; //当某条链表中元素的个数大于8时//将转变为红黑树
transient int size;  
int threshold;      //阈值，即当table中元素个数大于这个值就要resize()
final float loadFactor;  //加载因子  
```
有些数据就看一眼就能懂的，需要另外注意的是：
	- **loadFactor(负载因子)**：负载因子声明了一个哈希表的装填程度。**负载因子的选择可以被认为是空间与时间上的一种折中**，这是因为当负载因子较高时，一个数组能够被填的越满，所以对整体来说，空间浪费会小（不管怎么样内存都已经把这部分的空间分配给了他），但同时查找速度因为值变多而降低；而当负载因子较小时，一个数组不会被填的太满，所以它整体上对空间的浪费较大，但是查找速度会因为值变少而加快。
	- **TREEIFY_THRESHOLD**：为了保证效率，当一个链表中的元素的数量大于这个阈值的时候，这个链表就会被变成一个红黑树。
- **HashMap查找的Complexity**: 要分析这个complexity很简单，hash function是o(1)，找到对应的位置是o(1)，如果有链表的话原来是o(n)，但是因为现在限制了链表的长度，所以查找最慢的地方在于搜索红黑树，而这个需要花上o(logn)，所以HashMap查找的complexity就是**o(logn)**
- **为什么HashMap会造成死锁**(<a href="https://blog.csdn.net/lantian0802/article/details/42487803">原文链接</a>)
	- 为了了解造成死锁的原因，首先要知道的是，为了防止一个数组过载，HashMap会经常自己检查自己的size是否超出阈值，如果超过的话，需要进行resize操作，而当resize的时候，是很简单的新建一个更大尺寸的hash表并且把数据从旧表中直接转移到新表，当转移的时候，以下的事情会发生：
		1. 对索引数组中的元素遍历
		2. 对链表上的每一个节点遍历：用 next 取得要转移那个元素的下一个，将 e 转移到新 Hash 表的头部，因为可能有元素，所以先将 e.next 指向新 Hash 表的第一个元素（如果是第一次就是 null)，这时候新 Hash 的第一个元素是 e，但是 Hash 指向的却是 e 没转移时候的第一个，所以需要将 Hash 表的第一个元素指向 e
		3. 循环2，直到链表节点全部转移
		4. 循环1，直到所有索引数组全部转移
	- 自己走一遍就不难发现，转移之后的链表和本来的链表顺序是相反的，而问题也出在这个地方。当多线程高并发的时候，当一个线程先完成对hash table的转移，那么链表有可能会形成环形链表，死锁就有可能会出现。

### Java基础知识
- JDK
- JRE
- JVM


